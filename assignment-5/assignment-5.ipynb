{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0 -1.0 -1.0 -25.0 -25.0 -25.0 -25.0]\n",
      " [-1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -25.0]\n",
      " [-1.0 -1.0 -25.0 -1.0 -25.0 -1.0 100.0]\n",
      " [-1.0 -25.0 -25.0 -1.0 -1.0 -25.0 -1.0]\n",
      " [-1.0 -1.0 -1.0 -25.0 -25.0 -25.0 -1.0]]\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.1f}\".format(x)}, threshold=sys.maxsize)\n",
    "\n",
    "# Global variables\n",
    "GOAL = (2,6)\n",
    "START = (2,0)\n",
    "WORLD = -1. * np.ones((5,7))\n",
    "OBSTACLES = [(0,3),(0,4),(0,5),(0,6),(1,6),(2,2),(2,4),(3,1),(3,2),(3,5),(4,3),(4,4),(4,5)]\n",
    "    \n",
    "# Populate world\n",
    "WORLD[GOAL] = 100\n",
    "\n",
    "for obstacle in OBSTACLES:\n",
    "    WORLD[obstacle] = -25\n",
    "\n",
    "print(WORLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.9\n",
    "GAMMA = 0.8\n",
    "\n",
    "# Move\n",
    "def move(state, action):\n",
    "    new_state = state.copy()\n",
    "    \n",
    "    # Right\n",
    "    if action == \"r\":\n",
    "        new_state[\"x\"] += 1\n",
    "    # Lower right\n",
    "    elif action == \"dr\":\n",
    "        new_state[\"x\"] += 1\n",
    "        new_state[\"y\"] += 1\n",
    "    # Down\n",
    "    elif action == \"d\":\n",
    "        new_state[\"y\"] += 1\n",
    "    # Lower left\n",
    "    elif action == \"dl\":\n",
    "        new_state[\"x\"] -= 1\n",
    "        new_state[\"y\"] += 1\n",
    "    # Left\n",
    "    elif action == \"l\":\n",
    "        new_state[\"x\"] -= 1\n",
    "    # Upper left\n",
    "    elif action == \"ul\":\n",
    "        new_state[\"x\"] -= 1\n",
    "        new_state[\"y\"] -= 1\n",
    "    # Up\n",
    "    elif action == \"u\":\n",
    "        new_state[\"y\"] -= 1\n",
    "    # Upper right\n",
    "    if action == \"ur\":\n",
    "        new_state[\"x\"] += 1\n",
    "        new_state[\"y\"] -= 1\n",
    "\n",
    "    return new_state\n",
    "\n",
    "# Check if state out of bound\n",
    "# and returns truncated state\n",
    "def truncate(state):\n",
    "    # Truncated state\n",
    "    new_state = state.copy()\n",
    "    \n",
    "    # Check if out of bounds\n",
    "    if new_state['y'] < 0:\n",
    "        new_state['y'] += 1\n",
    "        \n",
    "    if new_state['y'] >= WORLD.shape[0]:\n",
    "        new_state['y'] -= 1\n",
    "            \n",
    "    if new_state['x'] < 0:\n",
    "        new_state['x'] += 1\n",
    "        \n",
    "    if new_state['x'] >= WORLD.shape[1]:\n",
    "        new_state['x'] -= 1\n",
    "    \n",
    "    return new_state\n",
    "\n",
    "# Check if state terminal\n",
    "def terminal(state):\n",
    "    return True if (state['y'], state['x']) == GOAL or \\\n",
    "                   (state['y'], state['x']) in OBSTACLES \\\n",
    "                else False\n",
    "\n",
    "# Step function\n",
    "def step(state, action):\n",
    "    # Returns\n",
    "    done = None\n",
    "    reward = None\n",
    "    \n",
    "    # Move based on action\n",
    "    new_state = move(state, action)\n",
    "    \n",
    "    # Check that state is valid\n",
    "    new_state = truncate(new_state)\n",
    "    \n",
    "    # Check if state is terminal\n",
    "    done = terminal(new_state)\n",
    "    \n",
    "    # Get reward for new state\n",
    "    reward = WORLD[new_state['y'], new_state['x']]\n",
    "    \n",
    "    return (new_state, reward, done)\n",
    "\n",
    "\n",
    "ACTIONS = {\n",
    "    'ur': [('ur', 0.8), ('u', 0.1), ('r', 0.1)],\n",
    "    'r': [('r', 0.8), ('ur', 0.1), ('dr', 0.1)], \n",
    "    'dr': [('dr', 0.8), ('r', 0.1), ('d', 0.1)]\n",
    "}\n",
    "\n",
    "def generate_action():\n",
    "    action = None\n",
    "    prob = np.random.uniform(0.0, 1.0)\n",
    "    \n",
    "    # Apply policy\n",
    "    if prob < 0.5:\n",
    "        action = 'ur' if prob > 0.25 else 'dr'\n",
    "    else:\n",
    "        action = 'r'\n",
    "        \n",
    "    # Apply non-det. action\n",
    "    prob = np.random.uniform(0.0, 1.0)\n",
    "    if prob < ACTIONS[action][0][1]:\n",
    "        action = ACTIONS[action][0][0]\n",
    "    else:\n",
    "        action = (ACTIONS[action][1][0] \n",
    "                  if prob > ACTIONS[action][1][1] \n",
    "                  else ACTIONS[action][2][0])\n",
    "    return action\n",
    "\n",
    "\n",
    "def TD_eval(loops=1000):\n",
    "    V = np.zeros_like(WORLD)\n",
    "\n",
    "    for count in range(loops): \n",
    "        s = {'y': START[0], 'x': START[1]}\n",
    "\n",
    "        # Episode loop\n",
    "        while True:\n",
    "            action = generate_action()\n",
    "            n_s, reward, done = step(s, action)\n",
    "                        \n",
    "            V[s['y'], s['x']] = (V[s['y'], s['x']] + ALPHA * \n",
    "                                (reward + GAMMA*V[n_s['y'], n_s['x']]-V[s['y'], s['x']]))\n",
    "            s = n_s\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-17.6, -15.2, -20.8, 0.0, 0.0, 0.0, 0.0],\n",
       "       [-17.5, -20.4, -7.9, 43.5, -5.1, -13.6, 0.0],\n",
       "       [-20.9, -21.3, 0.0, -23.1, 0.0, -24.0, 0.0],\n",
       "       [0.0, 0.0, 0.0, 0.0, -24.1, 0.0, 99.9],\n",
       "       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.5]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = TD_eval()\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
