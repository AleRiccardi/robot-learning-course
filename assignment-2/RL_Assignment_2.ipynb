{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Sheet 2\n",
    "## Solution examples\n",
    "\n",
    "## Task 2.1) \n",
    "Given is a seven-armed bandit, as introduced in the lecture.\n",
    "\n",
    "The first arm shall sample its reward uniformly from the interval $[-4, 3)$.\n",
    "\n",
    "The second arm shall sample its reward uniformly from $[1, 5)$.\n",
    "\n",
    "The third arm shall sample its reward uniformly from the interval $[2, 3)$.\n",
    "\n",
    "The fourth arm shall sample its reward uniformly from $[–2, 5)$.\n",
    "\n",
    "The fifth arm shall sample its reward uniformly from $[0, 4)$.\n",
    "\n",
    "The sixth arm shall sample its reward uniformly from $[1, 4)$.\n",
    "\n",
    "The seventh arm shall sample its reward uniformly from $[3, 7)$.\n",
    "\n",
    "### What is the expected reward when actions are chosen uniformly?\n",
    "\n",
    "First, we calculate the expected value of each arm individually:\n",
    "\n",
    "Arm 1: $0.5\\cdot(-4+3)=-0.5$\n",
    "\n",
    "Arm 2: $0.5\\cdot(1+5)=3$\n",
    "\n",
    "Arm 3: $0.5\\cdot(2+3)=2.5$\n",
    "\n",
    "Arm 4: $0.5\\cdot(-2+5)=1.5$\n",
    "\n",
    "Arm 5: $0.5\\cdot(0+4)=2$\n",
    "\n",
    "Arm 6: $0.5\\cdot(1+4)=2.5$\n",
    "\n",
    "Arm 7: $0.5\\cdot(3+7)=5$\n",
    "\n",
    "Clearly, pulling 7 is the optimal action.\n",
    "\n",
    "Finally, we form the expectation over sampling these arms uniformly:\n",
    "\n",
    "$\\frac{1}{7}\\cdot (-0.5) + \\frac{1}{7}\\cdot 3 + \\frac{1}{7}\\cdot 2.5 + \\frac{1}{7}\\cdot1.5 + \\frac{1}{7}\\cdot2 + \\frac{1}{7}\\cdot2.5 + \\frac{1}{7}\\cdot5 \\approx 2.29$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2)\n",
    "Implement the seven-armed bandit from $\\textbf{2.1)}$!\n",
    "\n",
    "Initialize $Q(a_i)=0$ and chose $2000$ actions according to an $\\epsilon$-greedy selection strategy ($\\epsilon=0.1$).\n",
    "\n",
    "Update your action values by computing the sample average reward of each action recursively.\n",
    "For every $100$ actions show the percentage of choosing arm $1$, arm $2$, arm $3$, arm $4$, arm $5$,\n",
    "arm $6$ and arm $7$ as well as the resulting average reward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(2020)\n",
    "\n",
    "def arm1():\n",
    "    return np.random.uniform(-4,3)\n",
    "def arm2():\n",
    "    return np.random.uniform(1,5)\n",
    "def arm3():\n",
    "    return np.random.uniform(2,3)\n",
    "def arm4():\n",
    "        return np.random.uniform(-2,5)\n",
    "def arm5():\n",
    "    return np.random.uniform(0,4)\n",
    "def arm6():\n",
    "    return np.random.uniform(1,4)\n",
    "def arm7():\n",
    "    return np.random.uniform(3,7)\n",
    "\n",
    "arm = [arm1, arm2, arm3, arm4, arm5, arm6, arm7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITER = 2000\n",
    "\n",
    "Q = np.zeros(7) #initialize Q with 0\n",
    "count = np.zeros(7) #this array counts how many times we selected each arm\n",
    "countPrev = count.copy() #using this array we can calculate how often each arm was selected in the last 100 steps\n",
    "rewards = np.empty(NUM_ITER) #here we can save the reward we get each iteration\n",
    "selectPercentage = np.empty((7,int(NUM_ITER/100)),'float') #here we can save the percentage of selecting each arm\n",
    "\n",
    "\n",
    "for t in range(NUM_ITER):\n",
    "    eps = np.random.uniform() #rollout a number to compare to epsilon\n",
    "    if eps < 0.1: #this is true with probability epsilon\n",
    "        a = np.random.randint(0,7) #exploratory action\n",
    "    else:\n",
    "        a = np.argmax(Q) #exploitative action\n",
    "    count[a] += 1 #increase the count for that arm\n",
    "    reward = arm[a]() #sample that arm\n",
    "    Q[a] += (reward-Q[a])/count[a] #update the Q value of that arm\n",
    "    \n",
    "    rewards[t] = reward #save the reward for later plotting\n",
    "    \n",
    "    \n",
    "    if t > 0 and (t+1)%100 == 0: #save the arm selection proportions for later plotting\n",
    "        for a in range(7):\n",
    "            selectPercentage[a][int(t/100)] = 0.01*(count[a] - countPrev[a])\n",
    "        countPrev = count.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we follow lecture $2$, slide $38$ and update $Q$ according to\n",
    "\n",
    "$Q_{t+1} = Q_{t} + \\frac{1}{t+1}\\cdot(r_{t+1} - Q_t)$.\n",
    "\n",
    "In our case, the target's weight $\\frac{1}{t+1}$ is represented by $\\frac{1}{count[a]}$, which we increment before using it in the update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(100,NUM_ITER+1,100), (0.9+0.1/7)*np.ones_like(selectPercentage[0]),'r--', linewidth = 0.5)\n",
    "for a in range(7):\n",
    "    plt.plot(np.arange(100,NUM_ITER+1,100), selectPercentage[a], label = \"arm \" + str(a+1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If learning was successful, our agent should select the optimal action with a probability of $1-\\epsilon$. In the remaining exploratory actions, the optimal action can be selected with a probability $\\epsilon \\cdot \\frac{1}{7}$. The sum of this should be the percentage of selecting the optimal action.\n",
    "\n",
    "In the above plot, we plot this expectation as a baseline (dashed red line). After some iterations, We can see that arm $7$ is selected more or less exactly as often as we believed it would. \n",
    "\n",
    "Below, we plot the running reward. Given $r$, the rewards vector from our code, the running reward $r_{running}$ is given by\n",
    "\n",
    "$r_{running}[t] = \\frac{1}{t+1}\\cdot\\sum_{i=0}^{t} r[i]$.\n",
    "\n",
    "It is simply the average over the rewards up until that iteration. I prefer showing this number as it moves more slowly than, for example, the average reward over the last $100$ steps, which is very jittery and harder to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optReward = 4.73\n",
    "plt.plot(np.arange(100,NUM_ITER+1,100), optReward*np.ones_like(selectPercentage[0]),'r--', linewidth = 0.5)\n",
    "runningAverage = np.divide(np.cumsum(rewards),np.arange(1,NUM_ITER+1))\n",
    "plt.plot(np.arange(1,NUM_ITER+1), runningAverage)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After learning has converged, our agent should select the most rewarding action $90\\%$ of the time. In these cases, we expect a reward of $5$. The remaining actions are exploratory, and thus yield an expected reward of about $2.29$ as calculated in $\\textbf{2.1)}$. In summary, we therefore predict the running average should converge to $0.9\\cdot5+0.1\\cdot2.29\\approx4.73$. We plot this value as a baseline (in dashed red) and see that our agent stabilizes near it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting Q: [-0.989  2.933  2.407  1.834  1.618  2.543  5.   ]\n",
      "Arm selection counts: [  30.  137.   31.   28.   36.   32. 1706.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Resulting Q:\", np.round(Q,3))\n",
    "\n",
    "print(\"Arm selection counts:\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the individual expectations from $\\textbf{2.1)}$ are not found yet. This is due to the low probability of exploratory actions. While arm $7$ has been greedily sampled very many times, the other arms have only been tested tens of times. Considering this, it is not very surprising that the agent has found the expected return of arm $7$ almost exactly, but is still relatively clueless regarding the other arms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.3)\n",
    "Consider a student taking an exam, which consists of $k$ tasks.\n",
    "For simplicity, we assume that the tasks $i = 1, … , k$ can either be solved, which results in the full\n",
    "number $r_i$ of points, or not be solved, resulting in zero points ($r_i = 0$).\n",
    "\n",
    "After working on a task, the student knows whether the task has been solved or not.\n",
    "\n",
    "The student may attempt to solve each task a second time, but only when it has not been solved\n",
    "before.\n",
    "\n",
    "For each attempt, the probability $p_i$ of solving the task shall be independent. It depends only on the difficulty of the task and is as follows:\n",
    "\n",
    "| Task $\\textit{i}$| Points $r_i$ | Solution probability $p_i$|\n",
    "|------------------|--------------|-------------------------------------------|\n",
    "|   1              | 8            |    0.15                                   |\n",
    "|   2              | 6            |    0.4                                    |\n",
    "|   3              | 10           |    0.25                                   |\n",
    "|   4              | 2            |    0.6                                    |\n",
    "|   5              | 7            |    0.35                                   |\n",
    "|   6              | 3            |    0.5                                    |\n",
    "|   7              | 20           |    0.2                                    |\n",
    "\n",
    "### Formulate this problem as a Markov Decision Process! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To specify a Markov Decision Process, we need to define a set of states $S$ and a set of actions $A(s)$, with $s\\in S$.\n",
    "\n",
    "$S$: The state space needs to sufficiently encode the history of our system. In this case, it is important not only to save which tasks have been solved (necessary because the student can only work on unsolved task), but also if a task has been attempted before (necessary because we have a maximum number of attempts). Therefore, we can simply define $s = (solved, attempted)$, with\n",
    "\n",
    "$solved := (i_1, i_2, ..., i_7)$, $i_j \\in \\{0,1\\}$, $i_j = 1 \\iff$ task j has been solved\n",
    "\n",
    "$attempted := (k_1, k_2, ..., k_7)$, $k_j \\in \\{0,1,2\\}$, $k_j :=$ number of attempts on task j.\n",
    "\n",
    "Below, we will refer to $i_j$ as $solved_j$ and $k_j$ as $attempted_j$. \n",
    "\n",
    "$A(s)$: Intuitively, the actions are to attempt to work on a task. Of course, this is only possible if the task has not been solved yet and not been attempted too often. Keeping this in mind:\n",
    "\n",
    "$A(s) \\subseteq \\{a_1, a_2, ..., a_7\\}$, with $a_j$ the action of attempting to work on task j and\n",
    "\n",
    "$a_j \\in A(s) \\iff solved_j \\neq 1 \\land attempted_j \\leq 1$.\n",
    "\n",
    "Next, we need to define transition probabilities $P_{ss'}^a$. Note that we define this only for actions and state transitions which are possible. For example, no action can 'unsolve' a task. Furthermore we cannot attempt task previously solved or twice failed. For these combinations of situations and actions, consider $P_{ss'}^a = 0$.\n",
    "\n",
    "For $P_{ss'}^{a_j}$ with $solved_i = solved'_i \\land attempted_i = attempted'_i$ for $i\\neq j$, $attempted'_j = attempted_j + 1$:\n",
    "\n",
    "$P_{ss'}^{a_j} := p_j$ if $solved_j \\neq solved'_j$\n",
    "\n",
    "$P_{ss'}^{a_j} := 1- p_j$ if $solved_j = solved'_j$\n",
    "\n",
    "Finally, we can define the reward probabilities. As before, we demand $solved_i = solved'_i \\land attempted_i = attempted'_i$ for $i\\neq j$, $attempted'_j = attempted_j + 1$ to restrict our attention to plausible transitions. In this case, we get:\n",
    "\n",
    "$R_{ss'}^{a_j} := r_j$ if $solved_j \\neq solved'_j$.\n",
    "\n",
    "In all other combinations of $s$,$s'$ and $a$, $R_{ss'}^{a_j} := 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.4)\n",
    "The student considers two policies for choosing the tasks:\n",
    "\n",
    "$\\pi_A$: work on the tasks in sequential order, according to index $i$.\n",
    "\n",
    "$\\pi_B$: work on the tasks in the order of increasing difficulty (decreasing solution probability).\n",
    "\n",
    "In both cases, the first non-solved task will be attempted again.\n",
    "\n",
    "### Compare the expected return of both policies! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem is a little easier than the scenario described above. Because only the first task that has been failed is attempted again, we do not need to store the number of attempts in each state on a per task basis. Here, it is sufficient to store if the student has used the second attempt so far. \n",
    "\n",
    "As usual, import required packages and set up the framework for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = np.array([8,6,10,2,7,3,20]) #r_i\n",
    "success_probabilities = np.array([0.15,0.4,0.25,0.6,0.35,0.5,0.2]) #p_i\n",
    "attempt = 0 #see above text\n",
    "completed_tasks = np.zeros_like(rewards) #solved component of state as in 2.3)\n",
    "passing_score = np.sum(rewards)*0.5 #needed to determine the probability of passing, not required here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we specify a policy, that is, a rule $\\pi(s,a)$ that maps each state $s$ to a distribution over available actions $a \\in A(s)$, we can calculate the expected return following that policy and the probability of passing the exam by examining all possible trajectories following that policy.\n",
    "\n",
    "To simplify this problem, we could assume that our given $\\pi$ is a deterministic policy. Then, each state has at most $2$ outcomes; one for failing the selected task and one for successfully solving it. This is readily represented by a binary tree, each edge weighted by the success probability (or its complement) of the task corresponding to the action selected by $\\pi$. \n",
    "\n",
    "Each leaf of this tree is reached with a probability determined by the products of the edges leading there. We could then identifiy each leaf (which represents a terminal state) that has enough tasks solved to achieve a passing score, and sum up over the probabilities of these leaves being reached. This probability is then equal to the probability of passing the exam. Furthermore, we can read off the total score at each leaf. This can also be weighted by the probability of reaching the leaf. A weighted sum over all leaves in this manner yields the expected return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described above we build a binary search tree for the deterministic policies described in this task. We represent the policy as a queue of tasks to be sequentially attempted. When a task is solved or has been failed when the second attempt is no longer available, it is popped from the front of the queue. Then, the next tasks are attempted until the queue is empty. We are only interested in the leaves of the search tree and can assign a probability of 1 to leaves that represent states with enough points to pass the exam. This probability (technically not part of the task) is propagated up to the root of the tree along with the total number of points at the leaf. \n",
    "\n",
    "This is most intuitively implemented using a recursion that stops when terminal states are reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def priority_agent_expected_reward(r, p, attempted, solved, pi):\n",
    "    expected_sum = np.array([0.0, 0.0])\n",
    "    #Are we in a terminal state?\n",
    "    if(len(pi) == 0):\n",
    "        #Value of the whole trajectory.\n",
    "        trajectory_reward = np.sum(r[solved > 0]) #sum up over the points for completed tasks\n",
    "        passing_probability = 0.0\n",
    "        #Is the value of this trajectory sufficient to pass the exam?\n",
    "        if trajectory_reward >= passing_score:\n",
    "            passing_probability = 1.0\n",
    "        return np.array([trajectory_reward, passing_probability]) #send this tuple upwards towards the root\n",
    "    #If the state is not terminal:\n",
    "    else:\n",
    "        task = pi[0] #Determine the task that we must now work on.\n",
    "        solved_success = solved.copy() \n",
    "        solved_success[task] += 1 #This would be s' if we succeed in solving the task\n",
    "        if(attempted != 0):\n",
    "            #No second attempt is left, we must pop the task from the queue no matter if we fail or not\n",
    "            success_score = priority_agent_expected_reward(r, p, attempted, solved_success, np.delete(pi, [0]))\n",
    "            failure_score = priority_agent_expected_reward(r, p, attempted, solved, np.delete(pi, [0]))\n",
    "            expected_sum += p[task] * success_score + (1 - p[task]) * failure_score\n",
    "        else:\n",
    "            #If the student fails here, the task can be attempted again\n",
    "            success_score = priority_agent_expected_reward(r, p, attempted, solved_success, np.delete(pi, [0]))\n",
    "            failure_score = priority_agent_expected_reward(r, p, attempted + 1, solved, pi)\n",
    "            expected_sum += p[task] * success_score + (1 - p[task]) * failure_score\n",
    "        \n",
    "        #For each non-terminal state, two states can result from taking the action; \n",
    "        #one if we succeed, one if we fail.\n",
    "        #For this reason, the expected sum decomposes into a success_score and a failure_score each turn\n",
    "        return expected_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our $r_i$ and $p_i$ are zero-indexed while we represent $\\pi$ by a list of task numbers, we define a little helper function to transform the task numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policify(numpy_array):\n",
    "    return numpy_array - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call this function on $\\pi_A$ and $\\pi_B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected [return, success] of the policy [1 2 3 4 5 6 7] is [16.627435  0.180866]\n",
      "The expected [return, success] of the policy [4 6 2 5 3 7 1] is [16.917592  0.194384]\n"
     ]
    }
   ],
   "source": [
    "policy_a = np.array([1, 2, 3, 4, 5, 6, 7])\n",
    "policy_b = np.array([4, 6, 2, 5, 3, 7, 1])\n",
    "print('The expected [return, success] of the policy', policy_a,'is',\n",
    "      priority_agent_expected_reward(rewards, success_probabilities, attempted=0, solved=completed_tasks, pi=policify(policy_a)))\n",
    "print('The expected [return, success] of the policy', policy_b,'is',\n",
    "      priority_agent_expected_reward(rewards, success_probabilities, attempted=0, solved=completed_tasks, pi=policify(policy_b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidently, $\\pi_B$ has a slightly higher expected return than $\\pi_A$. The probability of passing the exam is slightly higher when following $\\pi_B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2  2.4  2.5  1.2  2.45 1.5  4.  ]\n"
     ]
    }
   ],
   "source": [
    "expected_rewards = np.multiply(rewards,success_probabilities)\n",
    "print(expected_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set $\\pi_C$ to the priority list of tasks ordered by decreasing expected reward. Then, calculate its return as in $\\textbf{2.3)}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected [return, success] of the policy [7 3 5 2 6 1 4] is [18.938897   0.2778135]\n"
     ]
    }
   ],
   "source": [
    "policy_c = np.array([7, 3, 5, 2, 6, 1, 4])\n",
    "print('The expected [return, success] of the policy', policy_c,'is', \n",
    "      priority_agent_expected_reward(rewards, success_probabilities, attempted=0, solved=completed_tasks, pi=policify(policy_c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the passing probability of the exam was not a part of the tasks, I just included it here because it highlights that our agent could potentially have different, but reasonable, objectives. We can also imagine a case where both of these objectives are not necessarily aligned. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.5)\n",
    "Give an example for a process model where the Markov assumption is not justified.\n",
    "\n",
    "How can the state be augmented to make the assumption valid again?\n",
    "\n",
    "Assume we are tracking $s_t = x_t\\in {\\rm I\\!R}$, the postion of a cart along a straight rail. If we want to predict the next position $s_{t+\\epsilon}$, we could calculate it as $x_{t} + \\epsilon \\cdot \\dot{x_t}$, but we do not know the velocity $\\dot{x_t}$. It could be estimated using the difference of $x_{t}$ and $x_{t-\\epsilon}$, but the latter is not stored in the state. In that sense, this process model is clearly not memory-less, we need part of its history before time $t$ to predict the distribution of future states.\n",
    "\n",
    "To fulfill the requirement of the Markov assumption again, we would need to augment the state to $s_t = (x_t, \\dot{x_t})$. Then, the information contained in the state is sufficient to predict the next state (for simplicity assuming constant acceleration of $0$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
